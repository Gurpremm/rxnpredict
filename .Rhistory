dim(plate.data) <- c(24,16)
plate.data2.2 <- t(plate.data)
# Plate 2.3
plate2.3 <- read.csv("yield_data\\plate2.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.3_pdt <- plate2.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.3_pdt))
dim(plate.data) <- c(24,16)
plate.data2.3 <- t(plate.data)
# Plate 2.4
plate2.4 <- read.csv("yield_data\\plate2.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.4_pdt <- plate2.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.4_pdt))
dim(plate.data) <- c(24,16)
plate.data2.4 <- t(plate.data)
# stitch Plate 2 together into one 32x48 matrix
plate2.top <- cbind(plate.data2.1, plate.data2.2)
plate2.bottom <- cbind(plate.data2.3, plate.data2.4)
plate2 <- rbind(plate2.top, plate2.bottom)
# Plate 3.1
plate3.1 <- read.csv("yield_data\\plate3.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.1_pdt <- plate3.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.1_pdt))
dim(plate.data) <- c(24,16)
plate.data3.1 <- t(plate.data)
# Plate 3.2
plate3.2 <- read.csv("yield_data\\plate3.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.2_pdt <- plate3.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.2_pdt))
dim(plate.data) <- c(24,16)
plate.data3.2 <- t(plate.data)
# Plate 3.3
plate3.3 <- read.csv("yield_data\\plate3.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.3_pdt <- plate3.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.3_pdt))
dim(plate.data) <- c(24,16)
plate.data3.3 <- t(plate.data)
# Plate 3.4
plate3.4 <- read.csv("yield_data\\plate3.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.4_pdt <- plate3.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.4_pdt))
dim(plate.data) <- c(24,16)
plate.data3.4 <- t(plate.data)
# stitch Plate 3 together into one 32x48 matrix
plate3.top <- cbind(plate.data3.1, plate.data3.2)
plate3.bottom <- cbind(plate.data3.3, plate.data3.4)
plate3 <- rbind(plate3.top, plate3.bottom)
# ============================================================================
# Make heatmaps and histograms
# ============================================================================
# Plate 1 heatmap and histogram
plate1.txt <- format(round(plate1, 0), nsmall = 0)
makeHeatmap1536(plate1, plate1.txt, "yield_data\\plate1_heatmap.png")
plate1 <- as.data.frame(plate1)
ggHist(plate1, "yield_data\\plate1_histogram.png")
# Plate 2 heatmap and histogram
plate2.txt <- format(round(plate2, 0), nsmall = 0)
makeHeatmap1536(plate2, plate2.txt, "yield_data\\plate2_heatmap.png")
plate2 <- as.data.frame(plate2)
ggHist(plate2, "yield_data\\plate2_histogram.png")
# Plate 3 heatmap and histogram
plate3.txt <- format(round(plate3, 0), nsmall = 0)
makeHeatmap1536(plate3, plate3.txt, "yield_data\\plate3_heatmap.png")
plate3 <- as.data.frame(plate3)
ggHist(plate3, "yield_data\\plate3_histogram.png")
# All plates histogram
top.two <- rbind(plate1, plate2)
all.plates <- rbind(top.two, plate3)
all.plates <- as.data.frame(all.plates)
ggHist(all.plates, "yield_data\\allplates_histogram.png")
# ============================================================================
# Load and prepare output table for modeling
# ============================================================================
# Remove reactions without additive and reactions with additive 7
plate1_nocontrols <- plate1[c(-1,-5,-9,-13,-20,-24,-28,-32), c(-16,-32,-48)]
# Remove reactions without aryl halide
plate2_nocontrols <- plate2[, c(-16,-32,-48)]
plate3_nocontrols <- plate3[, c(-16,-32,-48)]
plate1_nocontrols_v <- as.vector(t(plate1_nocontrols))
plate2_nocontrols_v <- as.vector(t(plate2_nocontrols))
plate3_nocontrols_v <- as.vector(t(plate3_nocontrols))
yield_data <- c(plate1_nocontrols_v, plate2_nocontrols_v, plate3_nocontrols_v)
# load output table generated by python script
output.table <- read.csv("R\\output_table.csv", header=TRUE)
# scale the descriptor data
output.scaled <- as.data.frame(scale(output.table))
# append the yield data from above
output.scaled$yield <- yield_data
# Uncomment and run line below to view large datasets
# utils::View(output.scaled)
# ============================================================================
# Subset the data to prepare for out-of-sample prediction
# ============================================================================
# separate into plates 1,2,3 and remove NA
output.plate1 <- output.scaled[1:1080, ]
output.plate1 <- output.plate1[!(is.na(output.plate1$yield)), ]
output.plate2 <- output.scaled[1081:2520, ]
output.plate2 <- output.plate2[!(is.na(output.plate2$yield)), ]
output.plate3 <- output.scaled[2521:3960, ]
output.plate3 <- output.plate3[!(is.na(output.plate3$yield)), ]
# separate by all 15 aryl halides
CF3.Cl <- seq(1, nrow(output.scaled), by=15)
CF3.Br <- seq(2, nrow(output.scaled), by=15)
CF3.I <- seq(3, nrow(output.scaled), by=15)
OMe.Cl <- seq(4, nrow(output.scaled), by=15)
OMe.Br <- seq(5, nrow(output.scaled), by=15)
OMe.I <- seq(6, nrow(output.scaled), by=15)
Et.Cl <- seq(7, nrow(output.scaled), by=15)
Et.Br <- seq(8, nrow(output.scaled), by=15)
Et.I <- seq(9, nrow(output.scaled), by=15)
pyr2.Cl <- seq(10, nrow(output.scaled), by=15)
pyr2.Br <- seq(11, nrow(output.scaled), by=15)
pyr2.I <- seq(12, nrow(output.scaled), by=15)
pyr3.Cl <- seq(13, nrow(output.scaled), by=15)
pyr3.Br <- seq(14, nrow(output.scaled), by=15)
pyr3.I <- seq(15, nrow(output.scaled), by=15)
# separate by chloride, bromide, iodide
ArCl <- seq(1, nrow(output.scaled), by=3)
ArCl.scaled <- output.scaled[ArCl, ]
ArCl.scaled <- ArCl.scaled[!(is.na(ArCl.scaled$yield)), ]
set.seed(8390)
size <- round(0.70*nrow(ArCl.scaled))
training <- sample(nrow(ArCl.scaled), size=size, replace=FALSE)
ArCl.training <- ArCl.scaled[training, ]
ArCl.test <- ArCl.scaled[-training, ]
ArBr <- seq(2, nrow(output.scaled), by=3)
ArBr.scaled <- output.scaled[ArBr, ]
ArBr.scaled <- ArBr.scaled[!(is.na(ArBr.scaled$yield)), ]
set.seed(9071)
size <- round(0.70*nrow(ArBr.scaled))
training <- sample(nrow(ArBr.scaled), size=size, replace=FALSE)
ArBr.training <- ArBr.scaled[training, ]
ArBr.test <- ArBr.scaled[-training, ]
ArI <- seq(3, nrow(output.scaled), by=3)
ArI.scaled <- output.scaled[ArI, ]
ArI.scaled <- ArI.scaled[!(is.na(ArI.scaled$yield)), ]
set.seed(6123)
size <- round(0.70*nrow(ArI.scaled))
training <- sample(nrow(ArI.scaled), size=size, replace=FALSE)
ArI.training <- ArI.scaled[training, ]
ArI.test <- ArI.scaled[-training, ]
# nonpyridyl aryl halides
nonpyridyl <- sort(c(CF3.Cl, CF3.Br, CF3.I, OMe.Cl, OMe.Br, OMe.I, Et.Cl, Et.Br, Et.I))
nonpyridyl.scaled <- output.scaled[nonpyridyl, ]
nonpyridyl.scaled <- nonpyridyl.scaled[!(is.na(nonpyridyl.scaled$yield)), ]
# pyridyl aryl halides
pyridyl <- sort(c(pyr2.Cl, pyr2.Br, pyr2.I, pyr3.Cl, pyr3.Br, pyr3.I))
pyridyl.scaled <- output.scaled[pyridyl, ]
pyridyl.scaled <- pyridyl.scaled[!(is.na(pyridyl.scaled$yield)), ]
# yields under 80% and over 80%
under80 <- output.scaled$yield<80
output.under80 <- output.scaled[under80, ]
output.under80 <- output.under80[!(is.na(output.under80$yield)), ]
output.over80 <- output.scaled[!under80, ]
output.over80 <- output.over80[!(is.na(output.over80$yield)), ]
# ============================================================================
# Remove reactions without yield data and make histogram
# ============================================================================
# remove rows where yield=NA
output.scaled <- output.scaled[!(is.na(output.scaled$yield)), ]
# Histogram for modeling yields (removed controls and additive 7)
ggHist(output.scaled$yield, "yield_data\\allplates_nocontrols_histogram.png")
# ============================================================================
# Data splitting for modeling
# ============================================================================
# Split into training and test set (70/30)
set.seed(1084)
size <- round(0.70*nrow(output.scaled))
training <- sample(nrow(output.scaled), size=size, replace=FALSE)
training.scaled <- output.scaled[training,]
test.scaled <- output.scaled[-training,]
# Create smaller partitions within training set (equal to 10, 20, etc. % of TOTAL data)
# Sampled from within training set to avoid using test set data
size2.5 <- round(0.025*nrow(output.scaled))
size5 <- round(0.05*nrow(output.scaled))
size10 <- round(0.10*nrow(output.scaled))
size20 <- round(0.20*nrow(output.scaled))
size30 <- round(0.30*nrow(output.scaled))
size40 <- round(0.40*nrow(output.scaled))
size50 <- round(0.50*nrow(output.scaled))
size60 <- round(0.60*nrow(output.scaled))
training2.5rows <- sample(nrow(training.scaled),size=size2.5,replace=FALSE)
training2.5 <- training.scaled[training2.5rows, ]
training5rows <- sample(nrow(training.scaled),size=size5,replace=FALSE)
training5 <- training.scaled[training5rows, ]
training10rows <- sample(nrow(training.scaled),size=size10,replace=FALSE)
training10 <- training.scaled[training10rows, ]
training20rows <- sample(nrow(training.scaled),size=size20,replace=FALSE)
training20 <- training.scaled[training20rows, ]
training30rows <- sample(nrow(training.scaled),size=size30,replace=FALSE)
training30 <- training.scaled[training30rows, ]
training40rows <- sample(nrow(training.scaled),size=size40,replace=FALSE)
training40 <- training.scaled[training40rows, ]
training50rows <- sample(nrow(training.scaled),size=size50,replace=FALSE)
training50 <- training.scaled[training50rows, ]
training60rows <- sample(nrow(training.scaled),size=size60,replace=FALSE)
training60 <- training.scaled[training60rows, ]
# 10-fold cross-validation
train_control <- trainControl(method="cv", number=10, savePredictions=TRUE)
# ============================================================================
# Read in previously trained models saved as .rds files
# ============================================================================
# Run to read in previously trained models
lmFit.reduced <- readRDS("rds\\lmFit_reduced.rds")
knnFit <- readRDS("rds\\knnFit.rds")
svmFit <- readRDS("rds\\svmFit.rds")
bayesglmFit <- readRDS("rds\\bayesglmFit.rds")
lmFit <- readRDS("rds\\lmFit.rds")
nnetFit <- readRDS("rds\\nnetFit.rds")
rfFit <- readRDS("rds\\rfFit.rds")
rfFit2.5 <- readRDS("rds\\rfFit2_5.rds")
rfFit5 <- readRDS("rds\\rfFit5.rds")
rfFit10 <- readRDS("rds\\rfFit10.rds")
rfFit20 <- readRDS("rds\\rfFit20.rds")
rfFit30 <- readRDS("rds\\rfFit30.rds")
rfFit40 <- readRDS("rds\\rfFit40.rds")
rfFit50 <- readRDS("rds\\rfFit50.rds")
rfFit60 <- readRDS("rds\\rfFit60.rds")
rfFit70 <- readRDS("rds\\rfFit70.rds")
rfFit.LOO <- readRDS("rds\\rfFit_LOO.rds")
rfFit.ArCl <- readRDS("rds\\rfFit_ArCl.rds")
rfFit.ArBr <- readRDS("rds\\rfFit_ArBr.rds")
rfFit.ArI <- readRDS("rds\\rfFit_ArI.rds")
rfFit.ArBr.all <- readRDS("rds\\rfFit_ArBr_all.rds")
rfFit.nonpyridyl <- readRDS("rds\\rfFit_nonpyridyl.rds")
rfFit.under80 <- readRDS("rds\\rfFit_under80.rds")
# ============================================================================
# Regularized linear regression: Lasso, Ridge, and Elastic Net
# ============================================================================
set.seed(1533)
x <- as.matrix(training.scaled[, 1:120])
x.test <- as.matrix(test.scaled[, 1:120])
y <- training.scaled[, 121]
y.test <- test.scaled[, 121]
fit.lasso <- glmnet(x, y, family="gaussian", alpha=1) # lasso
fit.elnet <- glmnet(x, y, family="gaussian", alpha=0.5) # elastic net
fit.ridge <- glmnet(x, y, family="gaussian", alpha=0) # ridge
for (i in 0:10) {
assign(paste("fit", i, sep=""), cv.glmnet(x, y, type.measure="mse",
alpha=i/10,family="gaussian"))
}
# Plot solution paths
png(filename="R\\plots\\regularization_solution_paths.png", width = 800, height = 1000)
par(mfrow=c(3,2))
plot(fit.lasso, xvar="lambda")
plot(fit10, main="LASSO")
plot(fit.ridge, xvar="lambda")
plot(fit0, main="Ridge")
plot(fit.elnet, xvar="lambda")
plot(fit2, main="Elastic Net")
dev.off()
# Predict y values and calculate RMSE and R^2 for range of alpha values
yhat0 <- predict(fit0, s=fit0$lambda.1se, newx=x.test) # ridge
yhat1 <- predict(fit1, s=fit1$lambda.1se, newx=x.test) # elastic net
yhat2 <- predict(fit2, s=fit2$lambda.1se, newx=x.test) # elastic net
yhat3 <- predict(fit3, s=fit3$lambda.1se, newx=x.test) # elastic net
yhat4 <- predict(fit4, s=fit4$lambda.1se, newx=x.test) # elastic net
yhat5 <- predict(fit5, s=fit5$lambda.1se, newx=x.test) # elastic net
yhat6 <- predict(fit6, s=fit6$lambda.1se, newx=x.test) # elastic net
yhat7 <- predict(fit7, s=fit7$lambda.1se, newx=x.test) # elastic net
yhat8 <- predict(fit8, s=fit8$lambda.1se, newx=x.test) # elastic net
yhat9 <- predict(fit9, s=fit9$lambda.1se, newx=x.test) # elastic net
yhat10 <- predict(fit10, s=fit10$lambda.1se, newx=x.test) # lasso
rmse0 <- rmse(yhat0, y.test)
rmse1 <- rmse(yhat1, y.test)
rmse2 <- rmse(yhat2, y.test)
rmse3 <- rmse(yhat3, y.test)
rmse4 <- rmse(yhat4, y.test)
rmse5 <- rmse(yhat5, y.test)
rmse6 <- rmse(yhat6, y.test)
rmse7 <- rmse(yhat7, y.test)
rmse8 <- rmse(yhat8, y.test)
rmse9 <- rmse(yhat9, y.test)
rmse10 <- rmse(yhat10, y.test)
rsquared0 <- cor(yhat0, y.test)
rsquared1 <- cor(yhat1, y.test)
rsquared2 <- cor(yhat2, y.test)
rsquared3 <- cor(yhat3, y.test)
rsquared4 <- cor(yhat4, y.test)
rsquared5 <- cor(yhat5, y.test)
rsquared6 <- cor(yhat6, y.test)
rsquared7 <- cor(yhat7, y.test)
rsquared8 <- cor(yhat8, y.test)
rsquared9 <- cor(yhat9, y.test)
rsquared10 <- cor(yhat10, y.test)
mfit1 <- cv.glmnet(x, y, type.measure="mse", alpha=0.01, family="gaussian")
mfit2 <- cv.glmnet(x, y, type.measure="mse", alpha=0.1, family="gaussian")
mfit3 <- cv.glmnet(x, y, type.measure="mse", alpha=0.2, family="gaussian")
mfit4 <- cv.glmnet(x, y, type.measure="mse", alpha=0.5, family="gaussian")
mfit5 <- cv.glmnet(x, y, type.measure="mse", alpha=1, family="gaussian")
mfit1.pred <- predict(mfit1, s=mfit1$lambda.1se, newx=x.test)
mfit2.pred <- predict(mfit2, s=mfit2$lambda.1se, newx=x.test)
mfit3.pred <- predict(mfit3, s=mfit3$lambda.1se, newx=x.test)
mfit4.pred <- predict(mfit4, s=mfit4$lambda.1se, newx=x.test)
mfit5.pred <- predict(mfit5, s=mfit5$lambda.1se, newx=x.test)
mfit1.rmse <- rmse(mfit1.pred, y.test)
mfit2.rmse <- rmse(mfit2.pred, y.test)
mfit3.rmse <- rmse(mfit3.pred, y.test)
mfit4.rmse <- rmse(mfit4.pred, y.test)
mfit5.rmse <- rmse(mfit5.pred, y.test)
mfit1.r2 <- cor(mfit1.pred, y.test)
mfit2.r2 <- cor(mfit2.pred, y.test)
mfit3.r2 <- cor(mfit3.pred, y.test)
mfit4.r2 <- cor(mfit4.pred, y.test)
mfit5.r2 <- cor(mfit5.pred, y.test)
# Plot RMSE and R^2 for different values of alpha
df <- data.frame(alpha = c('0 (LASSO)', '0.01', '0.1', '0.2', '0.5', '1 (Ridge)'),
rmse = c(rmse0, mfit1.rmse, mfit2.rmse, mfit3.rmse, mfit4.rmse, mfit5.rmse),
r2 = c(rsquared0, mfit1.r2, mfit2.r2, mfit3.r2, mfit4.r2, mfit5.r2))
rmse.plot <- ggplot(df, aes(x=rmse, y=alpha)) +
geom_point() +
geom_text(label=round(df$rmse, 2), vjust=-1, size=3) +
labs(x='RMSE', y='alpha') +
xlim(15,16.5)
r2.plot <- ggplot(df, aes(x=r2, y=alpha)) +
geom_point() +
geom_text(label=round(df$r2, 4), vjust=-1, size=3) +
labs(x='Rsquared', y='alpha') +
xlim(0.8, 0.82)
plots <- arrangeGrob(rmse.plot, r2.plot, ncol=2)
ggsave(plots, file="R\\plots\\regularized_models.png", width=8, height=3)
# ============================================================================
# Dimension reduction by removing correlated descriptors
# ============================================================================
# Read in data for each reaction component
# These tables contain 1 row per different molecule (e.g., 22 rows in additive.csv)
additive <- read.csv("R\\additive.csv", header=TRUE)
aryl.halide <- read.csv("R\\aryl_halide.csv", header=TRUE)
base <- read.csv("R\\base.csv", header=TRUE)
ligand <- read.csv("R\\ligand.csv", header=TRUE)
# Correlation plots
ggcorr(additive, label=TRUE, alpha=0)
ggsave(file="R\\plots\\additive_corrplot.png", width=10, height=10)
ggcorr(aryl.halide, label=TRUE, alpha=0)
ggsave(file="R\\plots\\aryl_halide_corrplot.png", width=10, height=10)
ggcorr(base, label=TRUE, alpha=0)
ggsave(file="R\\plots\\base_corrplot.png", width=5, height=5)
ggcorr(ligand, label=FALSE, alpha=0)
ggsave(file="R\\plots\\ligand_corrplot.png", width=25, height=25)
# Feature selection by removing correlated features
# remove name column (need to do for cor function)
additive.num <- additive[, -which(names(additive)=="name")]
aryl.halide.num <- aryl.halide[, -which(names(aryl.halide)=="name")]
base.num <- base[, -which(names(base)=="name")]
ligand.num <- ligand[, -which(names(ligand)=="name")]
# additive
additive.bad <- findCorrelation(cor(additive.num), cutoff = 0.50, exact = TRUE)
additive.good <- names(additive.num[, -additive.bad])
additive.reduced <- additive.num[, additive.good]
pca.additive.reduced <- prcomp(additive.reduced)
plot(pca.additive.reduced)
ggcorr(additive.reduced, label=TRUE, alpha=0)
ggsave(file="R\\plots\\additive_reduced_corrplot.png", width=6, height=6)
# aryl halide
aryl.halide.bad <- findCorrelation(cor(aryl.halide.num), cutoff = 0.50, exact = TRUE)
aryl.halide.good <- names(aryl.halide.num[, -aryl.halide.bad])
aryl.halide.reduced <- aryl.halide.num[, aryl.halide.good]
pca.aryl.halide.reduced <- prcomp(aryl.halide.reduced)
plot(pca.aryl.halide.reduced)
ggcorr(aryl.halide.reduced, label=TRUE, alpha=0)
ggsave(file="R\\plots\\aryl_halide_reduced_corrplot.png", width=6, height=6)
# base
base.bad <- findCorrelation(cor(base.num), cutoff = 0.50, exact = TRUE)
base.good <- names(base.num[, -base.bad])
base.reduced <- base.num[, base.good]
pca.base.reduced <- prcomp(base.reduced)
plot(pca.base.reduced)
ggcorr(base.reduced, label=TRUE, alpha=0)
ggsave(file="R\\plots\\base_reduced_corrplot.png", width=3, height=3)
# ligand
ligand.bad <- findCorrelation(cor(ligand.num), cutoff = 0.50, exact = TRUE)
ligand.good <- names(ligand.num[, -ligand.bad])
ligand.reduced <- ligand.num[, ligand.good]
pca.ligand.reduced <- prcomp(ligand.reduced)
plot(pca.ligand.reduced)
ggcorr(ligand.reduced, label=TRUE, alpha=0)
ggsave(file="R\\plots\\ligand_reduced_corrplot.png", width=4, height=4)
# Subset to smaller number of dimensions
reduced.vars = c(names(additive.reduced),
names(aryl.halide.reduced),
names(base.reduced),
names(ligand.reduced),
"yield")
training.scaled.reduced <- training.scaled[, reduced.vars]
test.scaled.reduced <- test.scaled[, reduced.vars]
# Train linear model using reduced set of descriptors
lmFit.reduced <- train(yield ~ ., data=training.scaled.reduced, trControl=train_control, method="lm")
saveRDS(lmFit.reduced, "rds\\lmFit_reduced.rds")
lmFit.reduced.pred <- predict(lmFit.reduced, test.scaled.reduced)
lmFit.reduced.rmse <- rmse(lmFit.reduced.pred, test.scaled.reduced$yield)
lmFit.reduced.r2 <- cor(lmFit.reduced.pred, test.scaled.reduced$yield)
df <- data.frame(x = lmFit.reduced.pred,
y = test.scaled.reduced$yield,
type = as.factor('Linear Model'))
p <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.4) +
scale_x_continuous(breaks = seq(-25,100,25), lim=c(-30, 100)) +
labs(x='Predicted Yield', y='Observed Yield') +
geom_segment(aes(x=0, xend=100, y=0, yend=100), linetype="dashed") +
geom_smooth(method="loess", se=FALSE)
ggsave(file="R\\plots\\lm_reduced.png", width=5, height=4)
# R^2 values
rf.pred2.5.r2 <- cor(rf.pred2.5, test.scaled$yield)
rf.pred5.r2 <- cor(rf.pred5, test.scaled$yield)
rf.pred10.r2 <- cor(rf.pred10, test.scaled$yield)
rf.pred20.r2 <- cor(rf.pred20, test.scaled$yield)
rf.pred30.r2 <- cor(rf.pred30, test.scaled$yield)
rf.pred40.r2 <- cor(rf.pred40, test.scaled$yield)
rf.pred50.r2 <- cor(rf.pred50, test.scaled$yield)
rf.pred60.r2 <- cor(rf.pred60, test.scaled$yield)
rf.pred70.r2 <- cor(rf.pred70, test.scaled$yield)
# RMSE
rf.pred2.5.rmse <- rmse(rf.pred2.5, test.scaled$yield)
rf.pred5.rmse <- rmse(rf.pred5, test.scaled$yield)
rf.pred10.rmse <- rmse(rf.pred10, test.scaled$yield)
rf.pred20.rmse <- rmse(rf.pred20, test.scaled$yield)
rf.pred30.rmse <- rmse(rf.pred30, test.scaled$yield)
rf.pred40.rmse <- rmse(rf.pred40, test.scaled$yield)
rf.pred50.rmse <- rmse(rf.pred50, test.scaled$yield)
rf.pred60.rmse <- rmse(rf.pred60, test.scaled$yield)
rf.pred70.rmse <- rmse(rf.pred70, test.scaled$yield)
# create data frame containing RMSE and R^2 data for sparsity models
df <- data.frame(rmse = c(rf.pred2.5.rmse,
rf.pred5.rmse,
rf.pred10.rmse,
rf.pred20.rmse,
rf.pred30.rmse,
rf.pred50.rmse,
rf.pred70.rmse),
r2 = c(rf.pred2.5.r2,
rf.pred5.r2,
rf.pred10.r2,
rf.pred20.r2,
rf.pred30.r2,
rf.pred50.r2,
rf.pred70.r2))
row.names(df) <- c('2.5%', '5%', '10%', '20%', '30%', '50%', '70%')
# Plot RMSE and R^2 data
rmse.plot <- ggplot(df, aes(y=reorder(rownames(df), -rmse), x=rmse)) +
geom_point() +
geom_text(label=round(df$rmse, 1), vjust=-1, size=2.5) +
labs(x='RMSE', y='Training Set Data') +
xlim(0, 20) +
coord_flip()
r2.plot <- ggplot(df, aes(y=reorder(rownames(df), -rmse), x=r2)) +
geom_point() +
geom_text(label=round(df$r2, 2), vjust=-1, size=2.5) +
labs(x='Rsquared', y='Training Set Data') +
xlim(0.7, 1) +
coord_flip()
plots <- arrangeGrob(r2.plot, rmse.plot, ncol=2)
ggsave(plots, file="R\\plots\\rf_sparsity_r2_rmse.png", width=6, height=2.5)
# Predict for testing set
rf.pred2.5 <- predict(rfFit2.5, test.scaled)
rf.pred5 <- predict(rfFit5, test.scaled)
rf.pred10 <- predict(rfFit10, test.scaled)
rf.pred20 <- predict(rfFit20, test.scaled)
rf.pred30 <- predict(rfFit30, test.scaled)
rf.pred40 <- predict(rfFit40, test.scaled)
rf.pred50 <- predict(rfFit50, test.scaled)
rf.pred60 <- predict(rfFit60, test.scaled)
rf.pred70 <- predict(rfFit70, test.scaled)
# R^2 values
rf.pred2.5.r2 <- cor(rf.pred2.5, test.scaled$yield)
rf.pred5.r2 <- cor(rf.pred5, test.scaled$yield)
rf.pred10.r2 <- cor(rf.pred10, test.scaled$yield)
rf.pred20.r2 <- cor(rf.pred20, test.scaled$yield)
rf.pred30.r2 <- cor(rf.pred30, test.scaled$yield)
rf.pred40.r2 <- cor(rf.pred40, test.scaled$yield)
rf.pred50.r2 <- cor(rf.pred50, test.scaled$yield)
rf.pred60.r2 <- cor(rf.pred60, test.scaled$yield)
rf.pred70.r2 <- cor(rf.pred70, test.scaled$yield)
# RMSE
rf.pred2.5.rmse <- rmse(rf.pred2.5, test.scaled$yield)
rf.pred5.rmse <- rmse(rf.pred5, test.scaled$yield)
rf.pred10.rmse <- rmse(rf.pred10, test.scaled$yield)
rf.pred20.rmse <- rmse(rf.pred20, test.scaled$yield)
rf.pred30.rmse <- rmse(rf.pred30, test.scaled$yield)
rf.pred40.rmse <- rmse(rf.pred40, test.scaled$yield)
rf.pred50.rmse <- rmse(rf.pred50, test.scaled$yield)
rf.pred60.rmse <- rmse(rf.pred60, test.scaled$yield)
rf.pred70.rmse <- rmse(rf.pred70, test.scaled$yield)
# create data frame containing RMSE and R^2 data for sparsity models
df <- data.frame(rmse = c(rf.pred2.5.rmse,
rf.pred5.rmse,
rf.pred10.rmse,
rf.pred20.rmse,
rf.pred30.rmse,
rf.pred50.rmse,
rf.pred70.rmse),
r2 = c(rf.pred2.5.r2,
rf.pred5.r2,
rf.pred10.r2,
rf.pred20.r2,
rf.pred30.r2,
rf.pred50.r2,
rf.pred70.r2))
row.names(df) <- c('2.5%', '5%', '10%', '20%', '30%', '50%', '70%')
# Plot RMSE and R^2 data
rmse.plot <- ggplot(df, aes(y=reorder(rownames(df), -rmse), x=rmse)) +
geom_point() +
geom_text(label=round(df$rmse, 1), vjust=-1, size=2.5) +
labs(x='RMSE', y='Training Set Data') +
xlim(0, 20) +
coord_flip()
r2.plot <- ggplot(df, aes(y=reorder(rownames(df), -rmse), x=r2)) +
geom_point() +
geom_text(label=round(df$r2, 2), vjust=-1, size=2.5) +
labs(x='Rsquared', y='Training Set Data') +
xlim(0.7, 1) +
coord_flip()
plots <- arrangeGrob(r2.plot, rmse.plot, ncol=2)
ggsave(plots, file="R\\plots\\rf_sparsity_r2_rmse.png", width=6, height=2.5)
